{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“Python 3.12.3”的单元格需要ipykernel包。\n",
      "\u001b[1;31m运行以下命令，将 \"ipykernel\" 安装到 Python 环境中。\n",
      "\u001b[1;31m命令: \"/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall\""
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "\n",
    "path_to_input_text = \"cor-demo-sample.txt\" # Replace this by your testing input data.\n",
    "\n",
    "def drop_empty_item(words):\n",
    "    return [word for word in words if word != '']\n",
    "\n",
    "def sort_dict_by_keys(d, reverse=True):\n",
    "    keys = list(d.keys())\n",
    "    keys.sort(reverse=reverse)\n",
    "    return [(key,d[key]) for key in keys]\n",
    "\n",
    "# Step 1: Tokenize the input text.\n",
    "paragraph = \"\"\n",
    "lines = []\n",
    "\n",
    "with open(path_to_input_text, \"r\", encoding='unicode_escape') as f:\n",
    "    for line in f.readlines():\n",
    "        lines.append(drop_empty_item(re.sub(\"[^a-zA-Z]\", \" \", line).split(\" \")))\n",
    "        paragraph += line\n",
    "\n",
    "paragraph = re.sub(\"[^a-zA-Z]\", \" \", paragraph)\n",
    "\n",
    "words = paragraph.split(\" \")\n",
    "words = drop_empty_item(words)\n",
    "word_pairs = []\n",
    "\n",
    "# Step 2: Count the frequency for each word in the text (you should complete this in your first-pass MapReduce).\n",
    "ctr=Counter(words)\n",
    "ctr = sort_dict_by_keys(ctr, False)\n",
    "single_key_freq = {}\n",
    "for tmp in ctr:\n",
    "    word = tmp[0]\n",
    "    cnt = tmp[1]\n",
    "    single_key_freq[word] = float(cnt)\n",
    "\n",
    "# Step 3: Count the frequency for each word pairs in the text (you should complete this in your second-pass MapReduce).\n",
    "for line in lines:\n",
    "    ctr = Counter(line)\n",
    "    ctr = sort_dict_by_keys(ctr, False)\n",
    "    words = [y[0] for y in ctr]\n",
    "    for id1 in range(len(words)):\n",
    "        for id2 in range(id1+1, len(words)):\n",
    "            word_pairs.append(words[id1]+\"/\"+words[id2])\n",
    "\n",
    "# Step 4: Calculate the COR(A, B) for each word pairs in the text (you should complete this in your second-pass MapReduce).\n",
    "ctr=Counter(word_pairs)\n",
    "df = DataFrame(columns=['word1', 'word2', 'COR'])\n",
    "for pair in ctr:\n",
    "    cnt = ctr[pair]\n",
    "    pair_freq = float(cnt)\n",
    "    words = pair.split(\"/\")\n",
    "    COR = pair_freq / (single_key_freq[words[0]] * single_key_freq[words[1]])\n",
    "    df.loc[len(df.index)] = [words[0], words[1], COR]\n",
    "df = df.sort_values(by = ['word1', 'word2'], ascending = (True, True))\n",
    "df.to_csv(\"result.csv\", index=False, header=False, sep ='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
